---
title: "p8105_hw2_fw2394"
author: "Fang Wang"
date: "2024-09-29"
output: github_document
editor_options: 
  chunk_output_type: console
---
# Problem 1
## Set up the working_directory: 
```{r working_directory}
setwd("/Users/fangwang/Downloads/P8105 Data Science I/p8105_hw2_fw2394")
```

## Load necessary libraries:
```{r library}
library (tidyverse)
library (dplyr)
library (readxl)
```

## Load the dataset:
```{r data_clean}
nyc_transit =
  read_csv ("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |> janitor::clean_names() |> 
  select (line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) |> 
mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )
str(nyc_transit)
```
**The dataset contains 19 variables, including line, station_name, station_latitude, station_longitude, route1 to route11, entry, vending, entrance_type, and ada. It has a total of 1,868 observations, meaning there are 1,868 rows and 19 columns.So far, I have performed the following steps to clean and organize the data. First, I converted all variable names to lowercase using janitor::clean_names(). Then, I selected the 19 relevant columns using the select() function. Finally, I transformed the entry variable from a character type ("YES" or "NO") to a logical type (TRUE or FALSE) using case_match(). As a result, the dataset is now tidier and more structured compared to the original version. **

## Find how many distinct stations:
```{r distinct_station}
combined_station_line = nyc_transit |> 
  mutate (station_name_line = paste (station_name, line, sep = " ")) 

unique_stations = 
  combined_station_line |> 
  select (station_name_line) |>
  distinct()
nrow(unique_stations)
```

## Find how many stations that are ADA compliant:
```{r ada}
ada_compliant =
  nyc_transit |> 
  filter (ada == "TRUE")
nrow(ada_compliant)
```

## Calcuate the proportion of stations without vending allow entrance:
```{r prop}
proportion_allow_entrance = nyc_transit |> 
  filter(vending == "NO") |>
  summarize(prop = mean(entry == "TRUE"))
print(proportion_allow_entrance)
```

## Reformat data so that route number and route name are distinctive varaibles:
```{r route_number_name}
nyc_transit_long = combined_station_line |> 
  mutate(across(route1:route11, as.character)) |> 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name"
  ) |> 
  select (route_number, route_name, station_name_line, everything())
head(nyc_transit_long)
```

## To find how many distinct stations serve the A train:
```{r A_train}
nyc_transit_long |> 
  filter (route_name == "A") |> 
  distinct(station_name_line) |> 
  count() 
```

## To find how many stations that serve the A train are ADA compliant:
```{r A_train_ADA}
nyc_transit_long |> 
  filter (route_name == "A", ada == "TRUE") |> 
  count() 
```

# Problem 2

## Load dataset "Mr. Trash Wheel" and clean_up:
```{r mr}
mr_trash_wheel = read_excel ("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter (!is.na(dumpster)) |> 
  select (-x15, -x16) |> 
  mutate(sports_balls = as.integer(round(sports_balls)))|> 
  mutate (
    source = "mr_trash_wheel"
  )
```

## Load dataset "Professor Trash Wheel" and clean_up:
```{r professional}
professional_trash_wheel = read_excel ("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip =1) |> 
  janitor::clean_names() |> 
  filter (!is.na(dumpster)) |> 
  mutate(year = as.character(year)) |> 
   mutate (
    source = "professional_trash_wheel",
    sports_balls = "NA"
  ) |> 
  relocate(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,polystyrene, cigarette_butts, glass_bottles, wrappers, sports_balls, homes_powered, source)
```

## Load dataset "Gwynnda Trash Wheel" and clean_up:
```{r Gwynnda}
gwynnda_trash_wheel = read_excel ("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter (!is.na(dumpster)) |> 
  mutate(year = as.character(year)) |> 
   mutate (
    source = "gwynnda_trash_wheel",
    glass_bottles = "NA",
    sports_balls = "NA"
  ) |> 
  relocate(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,polystyrene, cigarette_butts, glass_bottles, wrappers, sports_balls, homes_powered,source)
```

## Combine Mr. Trash Wheel and Professional Trash Wheel:
```{r combined_mr_prof}
mr_prof_gwy = rbind (mr_trash_wheel, 
                     professional_trash_wheel, 
                     gwynnda_trash_wheel)
```
**The final dataset "mr_prof_gwy" contains 845 observations and 15 variables including additional variable called "source".**

## Calculate the total weight of trash collected by Professor Trash Wheel:
```{r total_prof}
mr_prof_gwy |> 
  filter(source == "professional_trash_wheel") |> 
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))
```

## Calculate the total number of cigarette butts collected by Gwynnda in June of 2022:
```{r cig_gwy}
mr_prof_gwy |> 
  filter(source == "gwynnda_trash_wheel", year == "2022", month =="June")|> 
  summarise(number_cig = sum(cigarette_butts, na.rm = TRUE))
```