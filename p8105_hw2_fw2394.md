p8105_hw2_fw2394
================
Fang Wang
2024-09-29

# Problem 1

## Set up the working_directory:

``` r
setwd("/Users/fangwang/Downloads/P8105 Data Science I/p8105_hw2_fw2394")
```

## Load necessary libraries:

``` r
library (tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library (dplyr)
library (readxl)
```

## Load the dataset:

``` r
nyc_transit =
  read_csv ("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |> janitor::clean_names() |> 
  select (line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) |> 
mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
str(nyc_transit)
```

    ## tibble [1,868 × 19] (S3: tbl_df/tbl/data.frame)
    ##  $ line             : chr [1:1868] "4 Avenue" "4 Avenue" "4 Avenue" "4 Avenue" ...
    ##  $ station_name     : chr [1:1868] "25th St" "25th St" "36th St" "36th St" ...
    ##  $ station_latitude : num [1:1868] 40.7 40.7 40.7 40.7 40.7 ...
    ##  $ station_longitude: num [1:1868] -74 -74 -74 -74 -74 ...
    ##  $ route1           : chr [1:1868] "R" "R" "N" "N" ...
    ##  $ route2           : chr [1:1868] NA NA "R" "R" ...
    ##  $ route3           : chr [1:1868] NA NA NA NA ...
    ##  $ route4           : chr [1:1868] NA NA NA NA ...
    ##  $ route5           : chr [1:1868] NA NA NA NA ...
    ##  $ route6           : chr [1:1868] NA NA NA NA ...
    ##  $ route7           : chr [1:1868] NA NA NA NA ...
    ##  $ route8           : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route9           : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route10          : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route11          : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ entry            : logi [1:1868] TRUE TRUE TRUE TRUE TRUE TRUE ...
    ##  $ vending          : chr [1:1868] "YES" "YES" "YES" "YES" ...
    ##  $ entrance_type    : chr [1:1868] "Stair" "Stair" "Stair" "Stair" ...
    ##  $ ada              : logi [1:1868] FALSE FALSE FALSE FALSE FALSE FALSE ...

**The dataset contains 19 variables, including line, station_name,
station_latitude, station_longitude, route1 to route11, entry, vending,
entrance_type, and ada. It has a total of 1,868 observations, meaning
there are 1,868 rows and 19 columns.So far, I have performed the
following steps to clean and organize the data. First, I converted all
variable names to lowercase using janitor::clean_names(). Then, I
selected the 19 relevant columns using the select() function. Finally, I
transformed the entry variable from a character type (“YES” or “NO”) to
a logical type (TRUE or FALSE) using case_match(). As a result, the
dataset is now tidier and more structured compared to the original
version. **

## Find how many distinct stations:

``` r
combined_station_line = nyc_transit |> 
  mutate (station_name_line = paste (station_name, line, sep = " ")) 

unique_stations = 
  combined_station_line |> 
  select (station_name_line) |>
  distinct()
nrow(unique_stations)
```

    ## [1] 465

## Find how many stations that are ADA compliant:

``` r
ada_compliant =
  nyc_transit |> 
  filter (ada == "TRUE")
nrow(ada_compliant)
```

    ## [1] 468

## Calcuate the proportion of stations without vending allow entrance:

``` r
proportion_allow_entrance = nyc_transit |> 
  filter(vending == "NO") |>
  summarize(prop = mean(entry == "TRUE"))
print(proportion_allow_entrance)
```

    ## # A tibble: 1 × 1
    ##    prop
    ##   <dbl>
    ## 1 0.377

## Reformat data so that route number and route name are distinctive varaibles:

``` r
nyc_transit_long = combined_station_line |> 
  mutate(across(route1:route11, as.character)) |> 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name"
  ) |> 
  select (route_number, route_name, station_name_line, everything()) 
  head(nyc_transit_long, 6)
```

    ## # A tibble: 6 × 11
    ##   route_number route_name station_name_line line   station_name station_latitude
    ##   <chr>        <chr>      <chr>             <chr>  <chr>                   <dbl>
    ## 1 route1       R          25th St 4 Avenue  4 Ave… 25th St                  40.7
    ## 2 route2       <NA>       25th St 4 Avenue  4 Ave… 25th St                  40.7
    ## 3 route3       <NA>       25th St 4 Avenue  4 Ave… 25th St                  40.7
    ## 4 route4       <NA>       25th St 4 Avenue  4 Ave… 25th St                  40.7
    ## 5 route5       <NA>       25th St 4 Avenue  4 Ave… 25th St                  40.7
    ## 6 route6       <NA>       25th St 4 Avenue  4 Ave… 25th St                  40.7
    ## # ℹ 5 more variables: station_longitude <dbl>, entry <lgl>, vending <chr>,
    ## #   entrance_type <chr>, ada <lgl>

## To find how many distinct stations serve the A train:

``` r
nyc_transit_long |> 
  filter (route_name == "A") |> 
  distinct(station_name_line) |> 
  count() 
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1    60

## To find how many stations that serve the A train are ADA compliant:

``` r
nyc_transit_long |> 
  filter (route_name == "A", ada == "TRUE") |> 
  count() 
```

    ## # A tibble: 1 × 1
    ##       n
    ##   <int>
    ## 1   107

# Problem 2

## Load dataset “Mr. Trash Wheel” and clean_up:

``` r
mr_trash_wheel = read_excel ("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter (!is.na(dumpster)) |> 
  select (-x15, -x16) |> 
  mutate(sports_balls = as.integer(round(sports_balls)))|> 
  mutate (
    source = "mr_trash_wheel"
  )
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## Load dataset “Professor Trash Wheel” and clean_up:

``` r
professional_trash_wheel = read_excel ("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter (!is.na(dumpster)) |> 
  mutate(year = as.character(year)) |> 
   mutate (
    source = "professional_trash_wheel",
    sports_balls = NA
  ) |> 
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered, source)
```

## Load dataset “Gwynnda Trash Wheel” and clean_up:

``` r
gwynnda_trash_wheel <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1)|> 
  janitor::clean_names() |> 
  filter (!is.na(dumpster)) |> 
  mutate(year = as.character(year)) |> 
   mutate (
    source = "gwynnda_trash_wheel",
    glass_bottles = NA,
    sports_balls = NA
  ) |> 
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered, source)
```

## Combine Mr. Trash Wheel and Professional Trash Wheel:

``` r
mr_prof_gwy = rbind (mr_trash_wheel, 
                     professional_trash_wheel, 
                     gwynnda_trash_wheel)
```

**The final dataset “mr_prof_gwy” contains 1033 observations and 15
variables including additional variable called “source”.**

## Calculate the total weight of trash collected by Professor Trash Wheel:

``` r
mr_prof_gwy |> 
  filter(source == "professional_trash_wheel") |> 
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         247.

## Calculate the total number of cigarette butts collected by Gwynnda in June of 2022:

``` r
mr_prof_gwy |> 
  filter(source == "gwynnda_trash_wheel", year == "2022", month =="June")|> 
  summarise(number_cig = sum(cigarette_butts, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   number_cig
    ##        <dbl>
    ## 1      18120

# Problem 3

## Load “bakers” dataset:

``` r
bakers = read_csv ("./data/gbb_datasets/bakers.csv") |> 
  janitor::clean_names() |> 
  separate(baker_name, into = c("first_name", "last_name"), sep = " ", extra = "merge")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Load “bakes” dataset:

``` r
bakes = read_csv ("./data/gbb_datasets/bakes.csv") |> 
  janitor::clean_names() |> 
  rename (
    first_name = "baker"
  )
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Combine the two datasets above:

``` r
combined_bakers =
  left_join(bakes, bakers, by = c("first_name", "series")) |> 
  arrange (series, episode) |> 
  select (series, episode, first_name, last_name, baker_age, everything())
```

## Load the dataset “results”:

``` r
results = 
  read_csv ("./data/gbb_datasets/results.csv", skip = 2) |> 
  mutate(
    result = case_match(
      result,
      "IN" ~"stayed_in",
      "OUT"~ "eliminated",
      "STAR BAKER" ~ "star_baker",
      "WINNER" ~ "series_winner",
      "Runner-up" ~ "series_runner-up",
      "WD" ~ "withdrew"
    )
  ) |> 
  mutate (
    star_baker = if_else (result == "star_baker", TRUE, NA),
    series_winner = if_else (result == "series_winner", TRUE, NA)
  ) |> 
  rename (
    first_name = "baker"
  )
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Combine to make the final dataset:

``` r
baker_final = 
  left_join (results, combined_bakers, by = c("first_name", "series", "episode")) |> 
  select (series, episode, first_name, last_name, baker_age, result, star_baker, series_winner, everything())
```

**In the data-cleaning process, I combined the first two datasets
(bakers and bakes) by the common variables: first_name and series. Then,
I combined all three datasets. Finally, the dataset contains 1136
observations and 13 variables.**

## create a table showing the star baker and winner of each episode:

``` r
baker_final |> 
  filter(series %in% 5:10) |> 
  filter(star_baker == TRUE | series_winner == TRUE) |> 
  select(series, episode, first_name, star_baker, series_winner) |> 
  knitr::kable()
```

| series | episode | first_name | star_baker | series_winner |
|-------:|--------:|:-----------|:-----------|:--------------|
|      5 |       1 | Nancy      | TRUE       | NA            |
|      5 |       2 | Richard    | TRUE       | NA            |
|      5 |       3 | Luis       | TRUE       | NA            |
|      5 |       4 | Richard    | TRUE       | NA            |
|      5 |       5 | Kate       | TRUE       | NA            |
|      5 |       6 | Chetna     | TRUE       | NA            |
|      5 |       7 | Richard    | TRUE       | NA            |
|      5 |       8 | Richard    | TRUE       | NA            |
|      5 |       9 | Richard    | TRUE       | NA            |
|      5 |      10 | Nancy      | NA         | TRUE          |
|      6 |       1 | Marie      | TRUE       | NA            |
|      6 |       2 | Ian        | TRUE       | NA            |
|      6 |       3 | Ian        | TRUE       | NA            |
|      6 |       4 | Ian        | TRUE       | NA            |
|      6 |       5 | Nadiya     | TRUE       | NA            |
|      6 |       6 | Mat        | TRUE       | NA            |
|      6 |       7 | Tamal      | TRUE       | NA            |
|      6 |       8 | Nadiya     | TRUE       | NA            |
|      6 |       9 | Nadiya     | TRUE       | NA            |
|      6 |      10 | Nadiya     | NA         | TRUE          |
|      7 |       1 | Jane       | TRUE       | NA            |
|      7 |       2 | Candice    | TRUE       | NA            |
|      7 |       3 | Tom        | TRUE       | NA            |
|      7 |       4 | Benjamina  | TRUE       | NA            |
|      7 |       5 | Candice    | TRUE       | NA            |
|      7 |       6 | Tom        | TRUE       | NA            |
|      7 |       7 | Andrew     | TRUE       | NA            |
|      7 |       8 | Candice    | TRUE       | NA            |
|      7 |       9 | Andrew     | TRUE       | NA            |
|      7 |      10 | Candice    | NA         | TRUE          |
|      8 |       1 | Steven     | TRUE       | NA            |
|      8 |       2 | Steven     | TRUE       | NA            |
|      8 |       3 | Julia      | TRUE       | NA            |
|      8 |       4 | Kate       | TRUE       | NA            |
|      8 |       5 | Sophie     | TRUE       | NA            |
|      8 |       6 | Liam       | TRUE       | NA            |
|      8 |       7 | Steven     | TRUE       | NA            |
|      8 |       8 | Stacey     | TRUE       | NA            |
|      8 |       9 | Sophie     | TRUE       | NA            |
|      8 |      10 | Sophie     | NA         | TRUE          |
|      9 |       1 | Manon      | TRUE       | NA            |
|      9 |       2 | Rahul      | TRUE       | NA            |
|      9 |       3 | Rahul      | TRUE       | NA            |
|      9 |       4 | Dan        | TRUE       | NA            |
|      9 |       5 | Kim-Joy    | TRUE       | NA            |
|      9 |       6 | Briony     | TRUE       | NA            |
|      9 |       7 | Kim-Joy    | TRUE       | NA            |
|      9 |       8 | Ruby       | TRUE       | NA            |
|      9 |       9 | Ruby       | TRUE       | NA            |
|      9 |      10 | Rahul      | NA         | TRUE          |
|     10 |       1 | Michelle   | TRUE       | NA            |
|     10 |       2 | Alice      | TRUE       | NA            |
|     10 |       3 | Michael    | TRUE       | NA            |
|     10 |       4 | Steph      | TRUE       | NA            |
|     10 |       5 | Steph      | TRUE       | NA            |
|     10 |       6 | Steph      | TRUE       | NA            |
|     10 |       7 | Henry      | TRUE       | NA            |
|     10 |       8 | Steph      | TRUE       | NA            |
|     10 |       9 | Alice      | TRUE       | NA            |
|     10 |      10 | David      | NA         | TRUE          |

**It is expected that individuals who win ‘Star Baker’ multiple times
are more likely to become the ‘Series Winner.’ However, it is surprising
that some contestants, like Richard, won ‘Star Baker’ several times but
never won the ‘Series Winner’**

## Load viewer dataset:

``` r
viewer = read_csv ("./data/gbb_datasets/viewers.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series_number",
    values_to = "viewership"
  )
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewer, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series_number viewership
    ##      <dbl> <chr>              <dbl>
    ##  1       1 series_1            2.24
    ##  2       1 series_2            3.1 
    ##  3       1 series_3            3.85
    ##  4       1 series_4            6.6 
    ##  5       1 series_5            8.51
    ##  6       1 series_6           11.6 
    ##  7       1 series_7           13.6 
    ##  8       1 series_8            9.46
    ##  9       1 series_9            9.55
    ## 10       1 series_10           9.62

## Calculate the average viewership in season 1:

``` r
viewer |> 
  filter (episode =="1") |> 
  summarise (viewership_mean_1 = mean (viewership))
```

    ## # A tibble: 1 × 1
    ##   viewership_mean_1
    ##               <dbl>
    ## 1              7.81

## Calculate the average viewership in season 5:

``` r
viewer |> 
  filter (episode =="5") |> 
  summarise (viewership_mean_5 = mean (viewership))
```

    ## # A tibble: 1 × 1
    ##   viewership_mean_5
    ##               <dbl>
    ## 1              8.04
